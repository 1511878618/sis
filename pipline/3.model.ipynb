{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/p300s/wangmx_group/xutingfeng/SIS/\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sis.model.transformer as trans \n",
    "from torch import nn\n",
    "from sis.model.embedding import OnehotLayer \n",
    "import torch.nn.functional as F\n",
    "import copy \n",
    "import torch \n",
    "\n",
    "c = copy.deepcopy\n",
    "\n",
    "class SisModle(nn.Module):\n",
    "    def __init__(self,N, d_model, d_ff, dropout, seq_length):\n",
    "        super(SisModle, self).__init__()\n",
    "\n",
    "        self.N = N \n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff \n",
    "        self.dropout = dropout\n",
    "        self.seq_length = seq_length\n",
    "        # embedding layer \n",
    "        self.onehot = OnehotLayer(d_model)\n",
    "        # basic layer \n",
    "        attn = trans.MultiHeadAttention(1, d_model)  # head as 1 \n",
    "        ff = trans.PositionwiseFeedForward(d_model, d_ff,dropout)\n",
    "        encoderlayer = trans.EncoderLayer(d_model, c(attn), c(ff), dropout)\n",
    "        # transformer encoder build \n",
    "        self.encoder_SLF = trans.Encoder(c(encoderlayer), N)\n",
    "        self.encoder_SRnase = trans.Encoder(c(encoderlayer), N)\n",
    "        # fc layer \n",
    "        self.fc1 = nn.Linear(d_model, 1)\n",
    "        self.fc2 = nn.Linear(seq_length, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_SLF = self.onehot(x[\"SLF_Seq_token\"])\n",
    "        x_SRnase = self.onehot(x[\"SRnase_Seq_token\"])\n",
    "\n",
    "        x_SLF = self.fc1(self.encoder_SLF(x_SLF, None))\n",
    "        x_SRnase = self.fc1(self.encoder_SRnase(x_SRnase, None))\n",
    "        \n",
    "        o = F.relu(torch.concat([x_SLF, x_SRnase], dim=1).squeeze(-1))\n",
    "        \n",
    "        last_mask = torch.concat([x[\"SLF_Seq_mask\"], x[\"SRnase_Seq_mask\"]], dim=1)\n",
    "        o = F.sigmoid(self.fc2(o.masked_fill(last_mask, 1e-9)))\n",
    "        \n",
    "        return o "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sis.dataset import SISDataset\n",
    "import torch \n",
    "import transformers \n",
    "\n",
    "sisdataset = SISDataset(root_dir=\"/p300s/wangmx_group/xutingfeng/SIS/sis/dataset/total_data.csv\")\n",
    "\n",
    "aa_vocab = sisdataset.aa_vocab\n",
    "sis_datasetDict = sisdataset.dataset_dict\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(sis_datasetDict[\"train\"], batch_size=4)\n",
    "test_dataloader = torch.utils.data.DataLoader(sis_datasetDict[\"test\"], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4 \n",
    "d_model = len(aa_vocab)\n",
    "d_ff = 64 \n",
    "dropout = 0.1 \n",
    "length = sisdataset.SLF_max_length + sisdataset.SRnase_max_length\n",
    "\n",
    "\n",
    "\n",
    "model = SisModle(N = N, d_model=d_model,d_ff=d_ff, dropout=dropout, seq_length=length) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/xtdisk/xueyb_group/xutingfeng/Anaconda/envs/torch/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5080],\n",
      "        [0.4833],\n",
      "        [0.5013],\n",
      "        [0.5058]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataloader:\n",
    "    y_pred = model(x)   \n",
    "    y_true = x[\"label\"]\n",
    " \n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "c = copy.deepcopy\n",
    "\n",
    "d_model = len(aa_vocab)\n",
    "d_ff = 64\n",
    "dropout = 0.1\n",
    "N = 4\n",
    "length = sisdataset.SLF_max_length + sisdataset.SRnase_max_length\n",
    "\n",
    "\n",
    "onehot = OnehotLayer(d_model)\n",
    "attn = trans.MultiHeadAttention(1, d_model)\n",
    "ff = trans.PositionwiseFeedForward(d_model, d_ff,dropout)\n",
    "encoderlayer = trans.EncoderLayer(d_model, c(attn), c(ff), dropout)\n",
    "encoder_SLF = trans.Encoder(c(encoderlayer), N)\n",
    "encoder_SRnase = trans.Encoder(c(encoderlayer), N)\n",
    "\n",
    "fc1 = nn.Linear(d_model, 1)\n",
    "fc2 = nn.Linear(length, 1)\n",
    "\n",
    "\n",
    "for x in train_dataloader:\n",
    "    x_SLF = onehot(x[\"SLF_Seq_token\"]).float()\n",
    "    x_SRnase = onehot(x[\"SRnase_Seq_token\"]).float()\n",
    "    y = x[\"label\"]\n",
    "    x_SLF = fc1(encoder_SLF(x_SLF, None))\n",
    "    x_SRnase = fc1(encoder_SRnase(x_SRnase, None))\n",
    "    \n",
    "    o = torch.concat([x_SLF, x_SRnase], dim=1).squeeze(-1)\n",
    "    \n",
    "    last_mask = torch.concat([x[\"SLF_Seq_mask\"], x[\"SRnase_Seq_mask\"]], dim=1)\n",
    "    o = fc2(o.masked_fill(last_mask, 1e-9))\n",
    "    print(o)\n",
    "\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0277e-01, 2.3571e-01, 4.9383e-01,  ..., 1.0000e-09, 1.0000e-09,\n",
       "         1.0000e-09],\n",
       "        [8.9821e-01, 8.3182e-01, 1.1953e+00,  ..., 1.0000e-09, 1.0000e-09,\n",
       "         1.0000e-09],\n",
       "        [9.5022e-01, 1.0824e+00, 6.6873e-01,  ..., 1.0000e-09, 1.0000e-09,\n",
       "         1.0000e-09],\n",
       "        [1.0430e+00, 8.0308e-01, 6.4187e-01,  ..., 1.0000e-09, 1.0000e-09,\n",
       "         1.0000e-09]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-52200760334198e7\n",
      "Reusing dataset csv (/home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b045ce02150148c7b43bbcd93275ec11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-bec2fd355b0cb7d7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-0f1986b4010acd7d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-fbd879c251d0f77b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-d7b3eee632703ea9.arrow\n",
      "Loading cached split indices for dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-fe11604753fbe9ea.arrow and /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-859c2defe8db73a3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5153],\n",
      "        [0.4990],\n",
      "        [0.5033],\n",
      "        [0.4975]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/xtdisk/xueyb_group/xutingfeng/Anaconda/envs/torch/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/p300s/wangmx_group/xutingfeng/SIS/\")\n",
    "\n",
    "from sis.dataset import SISDataset\n",
    "import torch \n",
    "import transformers \n",
    "from sis.model.sismodel import DoubleTransformerModel\n",
    "\n",
    "sisdataset = SISDataset(root_dir=\"/p300s/wangmx_group/xutingfeng/SIS/sis/dataset/total_data.csv\")\n",
    "\n",
    "aa_vocab = sisdataset.aa_vocab\n",
    "sis_datasetDict = sisdataset.dataset_dict\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(sis_datasetDict[\"train\"], batch_size=4)\n",
    "test_dataloader = torch.utils.data.DataLoader(sis_datasetDict[\"test\"], batch_size=4)\n",
    "\n",
    "N = 4 \n",
    "d_model = len(aa_vocab)\n",
    "d_ff = 64 \n",
    "dropout = 0.1 \n",
    "length = sisdataset.SLF_max_length + sisdataset.SRnase_max_length\n",
    "\n",
    "model = DoubleTransformerModel(N = N, d_model=d_model,d_ff=d_ff, dropout=dropout, seq_length=length) \n",
    "\n",
    "\n",
    "for x in train_dataloader:\n",
    "    y_pred = model(x)   \n",
    "    y_true = x[\"label\"]\n",
    " \n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['SLF', 'SLF_Seq', 'SRnase', 'SRnase_Seq', 'label', 'SLF_Seq_token', 'SRnase_Seq_token', 'SLF_Seq_mask', 'SRnase_Seq_mask'],\n",
       "        num_rows: 59\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['SLF', 'SLF_Seq', 'SRnase', 'SRnase_Seq', 'label', 'SLF_Seq_token', 'SRnase_Seq_token', 'SLF_Seq_mask', 'SRnase_Seq_mask'],\n",
       "        num_rows: 15\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sis_datasetDict.set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29d64b9f22f3e4a9a4b366339e885cc706a611874a6ccdca25799fb00f02ac96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
