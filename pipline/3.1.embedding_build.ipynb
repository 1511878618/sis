{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/p300s/wangmx_group/xutingfeng/SIS/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-52200760334198e7\n",
      "Reusing dataset csv (/home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c59f83973e849caa9725c49e2b244b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-d7b3eee632703ea9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-bec2fd355b0cb7d7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-0f1986b4010acd7d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-fbd879c251d0f77b.arrow\n",
      "Loading cached split indices for dataset at /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f445a5304f7ba125.arrow and /home/xutingfeng/.cache/huggingface/datasets/csv/default-52200760334198e7/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-cfda44d28db5f2dc.arrow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sis.dataset import SISDataset\n",
    "import torch \n",
    "import transformers \n",
    "from sis.model.sismodel import DoubleTransformerModel\n",
    "from sis.utils import modelParametersNum, try_gpu\n",
    "\n",
    "# Step1 dataset load \n",
    "# device = try_gpu()\n",
    "device = \"cuda:1\"\n",
    "\n",
    "sisdataset = SISDataset(root_dir=\"/p300s/wangmx_group/xutingfeng/SIS/sis/dataset/total_data.csv\", device = device)\n",
    "\n",
    "aa_vocab = sisdataset.aa_vocab\n",
    "sis_datasetDict = sisdataset.dataset_dict\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(sis_datasetDict[\"train\"], batch_size=4, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(sis_datasetDict[\"test\"], batch_size=4, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.],\n",
       "       [1., 2., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "aa_embedding_dict = {aa:[1, 2, 3] for aa in aa_vocab.get_itos()}\n",
    "\n",
    "aa_token_embedding_dict = {aa_vocab.lookup_indices([aa])[0]:value for aa, value in aa_embedding_dict.items()}\n",
    "\n",
    "sorted_embeeding_tuple = sorted(aa_token_embedding_dict.items(), key = lambda x: x[0]) # (tokens, values) sorted by token at ascending order\n",
    "sorted_embedding_array = np.stack([value for token, value in sorted_embeeding_tuple]).astype(np.float32)\n",
    "sorted_embedding_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 22])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_ = F.one_hot(torch.tensor([1, 0]), 22)\n",
    "input_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5484, 0.0738, 0.7047, 0.3437, 0.3530],\n",
       "        [0.4896, 0.3018, 0.5982, 0.7547, 0.9737]], dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_@sorted_embedding_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "import numpy as np \n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    EmbeddingLayer 传入aa_embeding_dict和aa_vocab\n",
    "    aa_embedding_dict is {\"A\":[1, 2, 3], ...}\n",
    "    aa_vocab is `torchtext.vocab.vocab.Vocab`\n",
    "\n",
    "    这两个包含的token应该是一致的\n",
    "\n",
    "    Example:\n",
    "        from sis.dataset.vocab import build_vocab_from_alphabet_dict\n",
    "        from sis.dataset.constants import BASE_AMINO_ACIDS\n",
    "\n",
    "        aa_vocab = build_vocab_from_alphabet_dict(BASE_AMINO_ACIDS)\n",
    "        aa_embedding_dict = {aa:np.random.randint(0, 5, size=(5)) for aa in aa_vocab.get_itos()}\n",
    "\n",
    "        EMLayer = EmbeddingLayer(aa_embedding_dict=aa_embedding_dict, aa_vocab=aa_vocab)\n",
    "\n",
    "        EMLayer(torch.tensor([1, 3, 5, 1, 2, 4]))\n",
    "    \"\"\"\n",
    "    def __init__(self, aa_embedding_dict, aa_vocab):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "\n",
    "        if len(aa_embedding_dict.keys()) != len(aa_vocab):\n",
    "            raise ValueError(\"aa_embedding_dict should contain all token in aa_vocab, check whether special tokens are in aa_embedding_dict!\")\n",
    "        \n",
    "        aa_token_embedding_dict = {aa_vocab.lookup_indices([aa])[0]:value for aa, value in aa_embedding_dict.items()}\n",
    "        \n",
    "        sorted_embeeding_tuple = sorted(aa_token_embedding_dict.items(), key = lambda x: x[0]) # (tokens, values) sorted by token at ascending order\n",
    "        sorted_embedding_array = np.stack([value for token, value in sorted_embeeding_tuple]).astype(np.float32)\n",
    "\n",
    "        self.sorted_embeeding_tuple = sorted_embeeding_tuple\n",
    "        self.w = torch.tensor(sorted_embedding_array)\n",
    "        self.d_model = self.w.shape[1]\n",
    "        self.tokens_num = self.w.shape[0]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_onehot = F.one_hot(x, self.tokens_num).float()\n",
    "        return x_onehot @ self.w \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': array([2, 2, 1, 4, 1]),\n",
       " '<pad>': array([3, 0, 1, 3, 4]),\n",
       " 'A': array([0, 2, 2, 3, 0]),\n",
       " 'C': array([3, 1, 0, 4, 2]),\n",
       " 'D': array([3, 2, 2, 3, 0]),\n",
       " 'E': array([3, 3, 3, 0, 0]),\n",
       " 'F': array([4, 4, 1, 3, 1]),\n",
       " 'G': array([3, 1, 2, 1, 2]),\n",
       " 'H': array([2, 0, 1, 2, 4]),\n",
       " 'I': array([3, 3, 0, 4, 4]),\n",
       " 'K': array([1, 0, 4, 3, 2]),\n",
       " 'L': array([3, 4, 3, 4, 4]),\n",
       " 'M': array([0, 2, 3, 4, 2]),\n",
       " 'N': array([2, 2, 1, 2, 4]),\n",
       " 'P': array([1, 2, 2, 0, 0]),\n",
       " 'Q': array([4, 1, 0, 3, 4]),\n",
       " 'R': array([4, 3, 1, 2, 2]),\n",
       " 'S': array([2, 1, 4, 4, 2]),\n",
       " 'T': array([4, 1, 2, 4, 4]),\n",
       " 'V': array([3, 1, 2, 0, 0]),\n",
       " 'W': array([2, 4, 1, 3, 1]),\n",
       " 'Y': array([1, 3, 0, 2, 0])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sis.dataset.vocab import build_vocab_from_alphabet_dict\n",
    "from sis.dataset.constants import BASE_AMINO_ACIDS\n",
    "\n",
    "aa_vocab = build_vocab_from_alphabet_dict(BASE_AMINO_ACIDS)\n",
    "aa_embedding_dict = {aa:np.random.randint(0, 5, size=(5)) for aa in aa_vocab.get_itos()}\n",
    "\n",
    "aa_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMLayer = EmbeddingLayer(aa_embedding_dict=aa_embedding_dict, aa_vocab=aa_vocab)\n",
    "EMLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 0., 1., 3., 4.],\n",
       "        [3., 1., 0., 4., 2.],\n",
       "        [3., 3., 3., 0., 0.],\n",
       "        [3., 0., 1., 3., 4.],\n",
       "        [0., 2., 2., 3., 0.],\n",
       "        [3., 2., 2., 3., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "EMLayer(torch.tensor([1, 3, 5, 1, 2, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.vocab.vocab.Vocab"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aa_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pka_cooh_alpha</th>\n",
       "      <th>pka_nh3</th>\n",
       "      <th>pka_rgroup</th>\n",
       "      <th>isoelectric_points</th>\n",
       "      <th>molecularweight</th>\n",
       "      <th>numbercodons</th>\n",
       "      <th>bulkiness</th>\n",
       "      <th>polarityzimmerman</th>\n",
       "      <th>polaritygrantham</th>\n",
       "      <th>refractivity</th>\n",
       "      <th>...</th>\n",
       "      <th>coilroux</th>\n",
       "      <th>alpha_helixlevitt</th>\n",
       "      <th>beta_sheetlevitt</th>\n",
       "      <th>beta_turnlevitt</th>\n",
       "      <th>totalbeta_strand</th>\n",
       "      <th>antiparallelbeta_strand</th>\n",
       "      <th>parallelbeta_strand</th>\n",
       "      <th>a_a_composition</th>\n",
       "      <th>a_a_swiss_prot</th>\n",
       "      <th>relativemutability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALA</th>\n",
       "      <td>2.35</td>\n",
       "      <td>9.87</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.11</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.25</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARG</th>\n",
       "      <td>2.18</td>\n",
       "      <td>9.09</td>\n",
       "      <td>13.20</td>\n",
       "      <td>10.76</td>\n",
       "      <td>174.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.28</td>\n",
       "      <td>52.00</td>\n",
       "      <td>10.5</td>\n",
       "      <td>26.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.68</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.53</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASN</th>\n",
       "      <td>2.18</td>\n",
       "      <td>9.09</td>\n",
       "      <td>13.20</td>\n",
       "      <td>10.76</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.82</td>\n",
       "      <td>3.38</td>\n",
       "      <td>11.6</td>\n",
       "      <td>13.28</td>\n",
       "      <td>...</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.06</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASP</th>\n",
       "      <td>1.88</td>\n",
       "      <td>9.60</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.98</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.68</td>\n",
       "      <td>49.70</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.197</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.45</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYS</th>\n",
       "      <td>1.71</td>\n",
       "      <td>10.78</td>\n",
       "      <td>8.33</td>\n",
       "      <td>5.02</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.46</td>\n",
       "      <td>1.48</td>\n",
       "      <td>5.5</td>\n",
       "      <td>35.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.37</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLN</th>\n",
       "      <td>2.17</td>\n",
       "      <td>9.13</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.65</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.45</td>\n",
       "      <td>3.53</td>\n",
       "      <td>10.5</td>\n",
       "      <td>17.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLU</th>\n",
       "      <td>2.19</td>\n",
       "      <td>9.67</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.08</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.57</td>\n",
       "      <td>49.90</td>\n",
       "      <td>12.3</td>\n",
       "      <td>17.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.75</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLY</th>\n",
       "      <td>2.34</td>\n",
       "      <td>9.60</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.06</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.251</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.79</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.07</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIS</th>\n",
       "      <td>1.78</td>\n",
       "      <td>8.97</td>\n",
       "      <td>5.97</td>\n",
       "      <td>7.64</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.69</td>\n",
       "      <td>51.60</td>\n",
       "      <td>10.4</td>\n",
       "      <td>21.81</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.27</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILE</th>\n",
       "      <td>2.32</td>\n",
       "      <td>9.76</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.04</td>\n",
       "      <td>131.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.2</td>\n",
       "      <td>19.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.60</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.96</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEU</th>\n",
       "      <td>2.36</td>\n",
       "      <td>9.60</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.04</td>\n",
       "      <td>131.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>0.13</td>\n",
       "      <td>4.9</td>\n",
       "      <td>18.78</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.42</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LYS</th>\n",
       "      <td>2.20</td>\n",
       "      <td>8.90</td>\n",
       "      <td>10.28</td>\n",
       "      <td>9.47</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>49.50</td>\n",
       "      <td>11.3</td>\n",
       "      <td>21.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.59</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.84</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MET</th>\n",
       "      <td>2.28</td>\n",
       "      <td>9.21</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.74</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.25</td>\n",
       "      <td>1.43</td>\n",
       "      <td>5.7</td>\n",
       "      <td>21.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.42</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHE</th>\n",
       "      <td>2.58</td>\n",
       "      <td>9.24</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.91</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.2</td>\n",
       "      <td>29.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.86</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRO</th>\n",
       "      <td>1.99</td>\n",
       "      <td>10.60</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>115.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.43</td>\n",
       "      <td>1.58</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1.540</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.70</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SER</th>\n",
       "      <td>2.21</td>\n",
       "      <td>9.15</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.68</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.47</td>\n",
       "      <td>1.67</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.35</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.56</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THR</th>\n",
       "      <td>2.15</td>\n",
       "      <td>9.12</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.60</td>\n",
       "      <td>119.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.77</td>\n",
       "      <td>1.66</td>\n",
       "      <td>8.6</td>\n",
       "      <td>11.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.59</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.34</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRP</th>\n",
       "      <td>2.38</td>\n",
       "      <td>9.39</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.88</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.4</td>\n",
       "      <td>42.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.08</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYR</th>\n",
       "      <td>2.20</td>\n",
       "      <td>9.11</td>\n",
       "      <td>10.07</td>\n",
       "      <td>5.63</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.03</td>\n",
       "      <td>1.61</td>\n",
       "      <td>6.2</td>\n",
       "      <td>31.53</td>\n",
       "      <td>...</td>\n",
       "      <td>1.109</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.08</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.92</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL</th>\n",
       "      <td>2.29</td>\n",
       "      <td>9.74</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.02</td>\n",
       "      <td>117.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.9</td>\n",
       "      <td>13.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.63</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.87</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pka_cooh_alpha  pka_nh3  pka_rgroup  isoelectric_points  molecularweight  \\\n",
       "ALA            2.35     9.87        7.00                6.11             89.0   \n",
       "ARG            2.18     9.09       13.20               10.76            174.0   \n",
       "ASN            2.18     9.09       13.20               10.76            132.0   \n",
       "ASP            1.88     9.60        3.65                2.98            133.0   \n",
       "CYS            1.71    10.78        8.33                5.02            121.0   \n",
       "GLN            2.17     9.13        7.00                5.65            146.0   \n",
       "GLU            2.19     9.67        4.25                3.08            147.0   \n",
       "GLY            2.34     9.60        7.00                6.06             75.0   \n",
       "HIS            1.78     8.97        5.97                7.64            155.0   \n",
       "ILE            2.32     9.76        7.00                6.04            131.0   \n",
       "LEU            2.36     9.60        7.00                6.04            131.0   \n",
       "LYS            2.20     8.90       10.28                9.47            146.0   \n",
       "MET            2.28     9.21        7.00                5.74            149.0   \n",
       "PHE            2.58     9.24        7.00                5.91            165.0   \n",
       "PRO            1.99    10.60        7.00                6.30            115.0   \n",
       "SER            2.21     9.15        7.00                5.68            105.0   \n",
       "THR            2.15     9.12        7.00                5.60            119.0   \n",
       "TRP            2.38     9.39        7.00                5.88            204.0   \n",
       "TYR            2.20     9.11       10.07                5.63            181.0   \n",
       "VAL            2.29     9.74        7.00                6.02            117.0   \n",
       "\n",
       "     numbercodons  bulkiness  polarityzimmerman  polaritygrantham  \\\n",
       "ALA           4.0      11.50               0.00               8.1   \n",
       "ARG           6.0      14.28              52.00              10.5   \n",
       "ASN           2.0      12.82               3.38              11.6   \n",
       "ASP           2.0      11.68              49.70              13.0   \n",
       "CYS           1.0      13.46               1.48               5.5   \n",
       "GLN           2.0      14.45               3.53              10.5   \n",
       "GLU           2.0      13.57              49.90              12.3   \n",
       "GLY           4.0       3.40               0.00               9.0   \n",
       "HIS           2.0      13.69              51.60              10.4   \n",
       "ILE           3.0      21.40               0.13               5.2   \n",
       "LEU           6.0      21.40               0.13               4.9   \n",
       "LYS           2.0      15.71              49.50              11.3   \n",
       "MET           1.0      16.25               1.43               5.7   \n",
       "PHE           2.0      19.80               0.35               5.2   \n",
       "PRO           4.0      17.43               1.58               8.0   \n",
       "SER           6.0       9.47               1.67               9.2   \n",
       "THR           4.0      15.77               1.66               8.6   \n",
       "TRP           1.0      21.67               2.10               5.4   \n",
       "TYR           2.0      18.03               1.61               6.2   \n",
       "VAL           4.0      21.57               0.13               5.9   \n",
       "\n",
       "     refractivity  ...  coilroux  alpha_helixlevitt  beta_sheetlevitt  \\\n",
       "ALA          4.34  ...     0.824               1.29              0.90   \n",
       "ARG         26.66  ...     0.893               0.96              0.99   \n",
       "ASN         13.28  ...     1.167               0.90              0.76   \n",
       "ASP         12.00  ...     1.197               1.04              0.72   \n",
       "CYS         35.77  ...     0.953               1.11              0.74   \n",
       "GLN         17.56  ...     0.947               1.27              0.80   \n",
       "GLU         17.26  ...     0.761               1.44              0.75   \n",
       "GLY          0.00  ...     1.251               0.56              0.92   \n",
       "HIS         21.81  ...     1.068               1.22              1.08   \n",
       "ILE         19.06  ...     0.886               0.97              1.45   \n",
       "LEU         18.78  ...     0.810               1.30              1.02   \n",
       "LYS         21.29  ...     0.897               1.23              0.77   \n",
       "MET         21.64  ...     0.810               1.47              0.97   \n",
       "PHE         29.40  ...     0.797               1.07              1.32   \n",
       "PRO         10.93  ...     1.540               0.52              0.64   \n",
       "SER          6.35  ...     1.130               0.82              0.95   \n",
       "THR         11.01  ...     1.148               0.82              1.21   \n",
       "TRP         42.53  ...     0.941               0.99              1.14   \n",
       "TYR         31.53  ...     1.109               0.72              1.25   \n",
       "VAL         13.92  ...     0.772               0.91              1.49   \n",
       "\n",
       "     beta_turnlevitt  totalbeta_strand  antiparallelbeta_strand  \\\n",
       "ALA             0.77              0.92                     0.90   \n",
       "ARG             0.88              0.93                     1.02   \n",
       "ASN             1.28              0.60                     0.62   \n",
       "ASP             1.41              0.48                     0.47   \n",
       "CYS             0.81              1.16                     1.24   \n",
       "GLN             0.98              0.95                     1.18   \n",
       "GLU             0.99              0.61                     0.62   \n",
       "GLY             1.64              0.61                     0.56   \n",
       "HIS             0.68              0.93                     1.12   \n",
       "ILE             0.51              1.81                     1.54   \n",
       "LEU             0.58              1.30                     1.26   \n",
       "LYS             0.96              0.70                     0.74   \n",
       "MET             0.41              1.19                     1.09   \n",
       "PHE             0.59              1.25                     1.23   \n",
       "PRO             1.91              0.40                     0.42   \n",
       "SER             1.32              0.82                     0.87   \n",
       "THR             1.04              1.12                     1.30   \n",
       "TRP             0.76              1.54                     1.75   \n",
       "TYR             1.05              1.53                     1.68   \n",
       "VAL             0.47              1.81                     1.53   \n",
       "\n",
       "     parallelbeta_strand  a_a_composition  a_a_swiss_prot  relativemutability  \n",
       "ALA                 1.00              8.3            8.25               100.0  \n",
       "ARG                 0.68              5.7            5.53                65.0  \n",
       "ASN                 0.54              4.4            4.06               134.0  \n",
       "ASP                 0.50              5.3            5.45               106.0  \n",
       "CYS                 0.91              1.7            1.37                20.0  \n",
       "GLN                 0.28              4.0            3.93                93.0  \n",
       "GLU                 0.59              6.2            6.75               102.0  \n",
       "GLY                 0.79              7.2            7.07                49.0  \n",
       "HIS                 0.38              2.2            2.27                66.0  \n",
       "ILE                 2.60              5.2            5.96                96.0  \n",
       "LEU                 1.42              9.0            9.66                40.0  \n",
       "LYS                 0.59              5.7            5.84                56.0  \n",
       "MET                 1.49              2.4            2.42                94.0  \n",
       "PHE                 1.30              3.9            3.86                41.0  \n",
       "PRO                 0.35              5.1            4.70                56.0  \n",
       "SER                 0.70              6.9            6.56               120.0  \n",
       "THR                 0.59              5.8            5.34                97.0  \n",
       "TRP                 0.89              1.3            1.08                18.0  \n",
       "TYR                 1.08              3.2            2.92                41.0  \n",
       "VAL                 2.63              6.6            6.87                74.0  \n",
       "\n",
       "[20 rows x 61 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"/p300s/wangmx_group/xutingfeng/SIS/sis/dataset/EmbeddingData/amino_acid_properties.csv\"\n",
    "\n",
    "expasy = pd.read_csv(path, sep=\",\",index_col=0).T\n",
    "expasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "aa_embedding_dict should contain all token in aa_vocab, check whether special tokens are in aa_embedding_dict!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/p300s/wangmx_group/xutingfeng/SIS/pipline/3.1.embedding_build.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpu03/p300s/wangmx_group/xutingfeng/SIS/pipline/3.1.embedding_build.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m aa_embedding_dict \u001b[39m=\u001b[39m load_expasy_embedding_dict()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpu03/p300s/wangmx_group/xutingfeng/SIS/pipline/3.1.embedding_build.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m aa_vocab \u001b[39m=\u001b[39m build_vocab_from_alphabet_dict(BASE_AMINO_ACIDS)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu03/p300s/wangmx_group/xutingfeng/SIS/pipline/3.1.embedding_build.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m EMLayer \u001b[39m=\u001b[39m EmbeddingLayer(aa_embedding_dict\u001b[39m=\u001b[39;49maa_embedding_dict, aa_vocab\u001b[39m=\u001b[39;49maa_vocab)\n",
      "File \u001b[0;32m/p300s/wangmx_group/xutingfeng/SIS/sis/model/embedding.py:43\u001b[0m, in \u001b[0;36mEmbeddingLayer.__init__\u001b[0;34m(self, aa_embedding_dict, aa_vocab)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39msuper\u001b[39m(EmbeddingLayer, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(aa_embedding_dict\u001b[39m.\u001b[39mkeys()) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(aa_vocab):\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     44\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maa_embedding_dict should contain all token in aa_vocab, check whether special tokens are in aa_embedding_dict!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     47\u001b[0m aa_token_embedding_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m     48\u001b[0m     aa_vocab\u001b[39m.\u001b[39mlookup_indices([aa])[\u001b[39m0\u001b[39m]: value\n\u001b[1;32m     49\u001b[0m     \u001b[39mfor\u001b[39;00m aa, value \u001b[39min\u001b[39;00m aa_embedding_dict\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     50\u001b[0m }\n\u001b[1;32m     52\u001b[0m sorted_embeeding_tuple \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\n\u001b[1;32m     53\u001b[0m     aa_token_embedding_dict\u001b[39m.\u001b[39mitems(), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39m]\n\u001b[1;32m     54\u001b[0m )  \u001b[39m# (tokens, values) sorted by token at ascending order\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: aa_embedding_dict should contain all token in aa_vocab, check whether special tokens are in aa_embedding_dict!"
     ]
    }
   ],
   "source": [
    "from sis.dataset.EmbeddingData.parse import load_expasy_embedding_dict, load_meiler_embedding_dict\n",
    "\n",
    "from sis.dataset.vocab import build_vocab_from_alphabet_dict\n",
    "from sis.dataset.constants import BASE_AMINO_ACIDS\n",
    "from sis.model.embedding import EmbeddingLayer\n",
    "\n",
    "aa_embedding_dict = load_expasy_embedding_dict()\n",
    "aa_vocab = build_vocab_from_alphabet_dict(BASE_AMINO_ACIDS)\n",
    "\n",
    "EMLayer = EmbeddingLayer(aa_embedding_dict=aa_embedding_dict, aa_vocab=aa_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': array([  2.35 ,   9.87 ,   7.   ,   6.11 ,  89.   ,   4.   ,  11.5  ,\n",
       "          0.   ,   8.1  ,   4.34 ,  78.   ,   0.62 ,  -0.4  ,  -0.5  ,\n",
       "          1.8  ,  12.97 ,   0.44 ,   0.616,   0.61 ,   0.31 ,   0.1  ,\n",
       "          0.3  ,   5.33 ,   1.36 ,   0.39 ,   0.62 ,   1.94 ,   1.15 ,\n",
       "         -0.3  ,   2.1  ,   0.42 ,   0.35 ,   5.1  ,   3.9  ,   7.3  ,\n",
       "          0.38 ,  -0.1  ,   0.5  ,  11.2  ,   6.6  ,   0.38 ,   0.74 ,\n",
       "          0.   ,  86.6  ,   0.36 ,   1.42 ,   0.83 ,   0.66 ,   1.489,\n",
       "          0.709,   0.788,   0.824,   1.29 ,   0.9  ,   0.77 ,   0.92 ,\n",
       "          0.9  ,   1.   ,   8.3  ,   8.25 , 100.   ]),\n",
       " 'R': array([ 2.180e+00,  9.090e+00,  1.320e+01,  1.076e+01,  1.740e+02,\n",
       "         6.000e+00,  1.428e+01,  5.200e+01,  1.050e+01,  2.666e+01,\n",
       "         9.500e+01, -2.530e+00, -5.900e-01,  3.000e+00, -4.500e+00,\n",
       "         1.172e+01, -2.420e+00,  0.000e+00,  6.900e-01, -1.010e+00,\n",
       "         1.910e+00, -1.400e+00,  4.180e+00,  1.500e-01, -3.950e+00,\n",
       "        -2.530e+00, -1.992e+01,  5.800e-01, -1.100e+00,  4.200e+00,\n",
       "        -1.560e+00, -1.500e+00,  2.000e+00,  3.200e+00, -3.600e+00,\n",
       "        -2.570e+00, -4.500e+00,  8.000e-01,  5.000e-01,  4.500e+00,\n",
       "         1.000e-02,  6.400e-01,  6.500e-01,  1.622e+02,  5.300e-01,\n",
       "         9.800e-01,  9.300e-01,  9.500e-01,  1.224e+00,  9.200e-01,\n",
       "         9.120e-01,  8.930e-01,  9.600e-01,  9.900e-01,  8.800e-01,\n",
       "         9.300e-01,  1.020e+00,  6.800e-01,  5.700e+00,  5.530e+00,\n",
       "         6.500e+01]),\n",
       " 'N': array([ 2.180e+00,  9.090e+00,  1.320e+01,  1.076e+01,  1.320e+02,\n",
       "         2.000e+00,  1.282e+01,  3.380e+00,  1.160e+01,  1.328e+01,\n",
       "         9.400e+01, -7.800e-01, -9.200e-01,  2.000e-01, -3.500e+00,\n",
       "         1.142e+01, -1.320e+00,  2.360e-01,  8.900e-01, -6.000e-01,\n",
       "         4.800e-01, -5.000e-01,  3.710e+00,  3.300e-01, -1.910e+00,\n",
       "        -7.800e-01, -9.680e+00, -7.700e-01, -2.000e-01,  7.000e+00,\n",
       "        -1.030e+00, -9.900e-01,  6.000e-01, -2.800e+00, -5.700e+00,\n",
       "        -1.620e+00, -1.600e+00,  8.000e-01,  2.900e+00,  6.700e+00,\n",
       "         1.200e-01,  6.300e-01,  1.330e+00,  1.033e+02,  4.600e-01,\n",
       "         6.700e-01,  8.900e-01,  1.560e+00,  7.720e-01,  6.040e-01,\n",
       "         1.572e+00,  1.167e+00,  9.000e-01,  7.600e-01,  1.280e+00,\n",
       "         6.000e-01,  6.200e-01,  5.400e-01,  4.400e+00,  4.060e+00,\n",
       "         1.340e+02]),\n",
       " 'D': array([ 1.880e+00,  9.600e+00,  3.650e+00,  2.980e+00,  1.330e+02,\n",
       "         2.000e+00,  1.168e+01,  4.970e+01,  1.300e+01,  1.200e+01,\n",
       "         8.100e+01, -9.000e-01, -1.310e+00,  3.000e+00, -3.500e+00,\n",
       "         1.085e+01, -3.100e-01,  2.800e-02,  6.100e-01, -7.700e-01,\n",
       "         7.800e-01, -6.000e-01,  3.590e+00,  1.100e-01, -3.810e+00,\n",
       "        -9.000e-02, -1.095e+01,  6.500e-01, -1.400e+00,  1.000e+01,\n",
       "        -5.100e-01, -2.150e+00,  7.000e-01, -2.800e+00, -2.900e+00,\n",
       "        -3.270e+00, -2.800e+00, -8.200e+00,  2.900e+00,  7.700e+00,\n",
       "         1.500e-01,  6.200e-01,  1.380e+00,  9.780e+01,  5.100e-01,\n",
       "         1.010e+00,  5.400e-01,  1.460e+00,  9.240e-01,  5.410e-01,\n",
       "         1.197e+00,  1.197e+00,  1.040e+00,  7.200e-01,  1.410e+00,\n",
       "         4.800e-01,  4.700e-01,  5.000e-01,  5.300e+00,  5.450e+00,\n",
       "         1.060e+02]),\n",
       " 'C': array([  1.71 ,  10.78 ,   8.33 ,   5.02 , 121.   ,   1.   ,  13.46 ,\n",
       "          1.48 ,   5.5  ,  35.77 ,  89.   ,   0.29 ,   0.17 ,  -1.   ,\n",
       "          2.5  ,  14.63 ,   0.58 ,   0.68 ,   0.36 ,   1.54 ,  -1.42 ,\n",
       "          0.9  ,   7.93 ,   1.27 ,   0.25 ,   0.29 ,  -1.24 ,  -1.2  ,\n",
       "          6.3  ,   1.4  ,   0.84 ,   0.76 ,   0.   , -14.3  ,  -9.2  ,\n",
       "         -0.3  ,  -2.2  ,  -6.8  ,   4.1  ,   0.9  ,   0.5  ,   0.91 ,\n",
       "          2.75 , 132.3  ,   0.35 ,   0.7  ,   1.19 ,   1.19 ,   0.966,\n",
       "          1.191,   0.965,   0.953,   1.11 ,   0.74 ,   0.81 ,   1.16 ,\n",
       "          1.24 ,   0.91 ,   1.7  ,   1.37 ,  20.   ]),\n",
       " 'Q': array([ 2.170e+00,  9.130e+00,  7.000e+00,  5.650e+00,  1.460e+02,\n",
       "         2.000e+00,  1.445e+01,  3.530e+00,  1.050e+01,  1.756e+01,\n",
       "         8.700e+01, -8.500e-01, -9.100e-01,  2.000e-01, -3.500e+00,\n",
       "         1.176e+01, -7.100e-01,  2.510e-01,  9.700e-01, -2.200e-01,\n",
       "         9.500e-01, -7.000e-01,  3.870e+00,  3.300e-01, -1.300e+00,\n",
       "        -8.500e-01, -9.380e+00, -1.100e-01, -2.000e-01,  6.000e+00,\n",
       "        -9.600e-01, -9.300e-01,  1.400e+00,  1.800e+00, -3.000e-01,\n",
       "        -1.840e+00, -2.500e+00, -4.800e+00,  1.600e+00,  5.200e+00,\n",
       "         7.000e-02,  6.200e-01,  8.900e-01,  1.192e+02,  4.900e-01,\n",
       "         1.110e+00,  1.100e+00,  9.800e-01,  1.164e+00,  8.400e-01,\n",
       "         9.970e-01,  9.470e-01,  1.270e+00,  8.000e-01,  9.800e-01,\n",
       "         9.500e-01,  1.180e+00,  2.800e-01,  4.000e+00,  3.930e+00,\n",
       "         9.300e+01]),\n",
       " 'E': array([ 2.190e+00,  9.670e+00,  4.250e+00,  3.080e+00,  1.470e+02,\n",
       "         2.000e+00,  1.357e+01,  4.990e+01,  1.230e+01,  1.726e+01,\n",
       "         7.800e+01, -7.400e-01, -1.220e+00,  3.000e+00, -3.500e+00,\n",
       "         1.189e+01, -3.400e-01,  4.300e-02,  5.100e-01, -6.400e-01,\n",
       "         8.300e-01, -7.000e-01,  3.650e+00,  2.500e-01, -2.910e+00,\n",
       "        -7.400e-01, -1.020e+01, -7.100e-01,  0.000e+00,  7.800e+00,\n",
       "        -3.700e-01, -1.950e+00,  1.800e+00, -7.500e+00, -7.100e+00,\n",
       "        -2.900e+00, -7.500e+00, -1.690e+01,  1.800e+00,  5.700e+00,\n",
       "         1.800e-01,  6.200e-01,  9.200e-01,  1.139e+02,  5.000e-01,\n",
       "         1.510e+00,  3.700e-01,  7.400e-01,  1.504e+00,  5.670e-01,\n",
       "         1.149e+00,  7.610e-01,  1.440e+00,  7.500e-01,  9.900e-01,\n",
       "         6.100e-01,  6.200e-01,  5.900e-01,  6.200e+00,  6.750e+00,\n",
       "         1.020e+02]),\n",
       " 'G': array([ 2.34 ,  9.6  ,  7.   ,  6.06 , 75.   ,  4.   ,  3.4  ,  0.   ,\n",
       "         9.   ,  0.   , 84.   ,  0.48 , -0.67 ,  0.   , -0.4  , 12.43 ,\n",
       "         0.   ,  0.501,  0.81 ,  0.   ,  0.33 ,  0.3  ,  4.48 ,  1.09 ,\n",
       "         0.   ,  0.48 ,  2.39 , -1.84 ,  1.2  ,  5.7  ,  0.   ,  0.   ,\n",
       "         4.1  , -2.3  , -1.2  , -0.19 , -0.5  ,  0.   , 11.8  ,  6.7  ,\n",
       "         0.36 ,  0.72 ,  0.74 , 62.9  ,  0.54 ,  0.57 ,  0.75 ,  1.56 ,\n",
       "         0.51 ,  0.657,  1.86 ,  1.251,  0.56 ,  0.92 ,  1.64 ,  0.61 ,\n",
       "         0.56 ,  0.79 ,  7.2  ,  7.07 , 49.   ]),\n",
       " 'H': array([ 1.780e+00,  8.970e+00,  5.970e+00,  7.640e+00,  1.550e+02,\n",
       "         2.000e+00,  1.369e+01,  5.160e+01,  1.040e+01,  2.181e+01,\n",
       "         8.400e+01, -4.000e-01, -6.400e-01, -5.000e-01, -3.200e+00,\n",
       "         1.216e+01, -1.000e-02,  1.650e-01,  6.900e-01,  1.300e-01,\n",
       "        -5.000e-01, -1.000e-01,  5.100e+00,  6.800e-01, -6.400e-01,\n",
       "        -4.000e-01, -1.027e+01,  3.120e+00, -1.300e+00,  2.100e+00,\n",
       "        -2.280e+00, -6.500e-01,  1.600e+00,  2.000e+00, -2.100e+00,\n",
       "        -1.440e+00,  8.000e-01, -3.500e+00,  2.000e+00,  2.500e+00,\n",
       "         1.700e-01,  7.800e-01,  5.800e-01,  1.558e+02,  3.200e-01,\n",
       "         1.000e+00,  8.700e-01,  9.500e-01,  1.003e+00,  8.630e-01,\n",
       "         9.700e-01,  1.068e+00,  1.220e+00,  1.080e+00,  6.800e-01,\n",
       "         9.300e-01,  1.120e+00,  3.800e-01,  2.200e+00,  2.270e+00,\n",
       "         6.600e+01]),\n",
       " 'I': array([ 2.320e+00,  9.760e+00,  7.000e+00,  6.040e+00,  1.310e+02,\n",
       "         3.000e+00,  2.140e+01,  1.300e-01,  5.200e+00,  1.906e+01,\n",
       "         8.800e+01,  1.380e+00,  1.250e+00, -1.800e+00,  4.500e+00,\n",
       "         1.567e+01,  2.460e+00,  9.430e-01, -1.450e+00,  1.800e+00,\n",
       "        -1.130e+00,  7.000e-01,  8.830e+00,  1.440e+00,  1.820e+00,\n",
       "         1.380e+00,  2.150e+00, -2.920e+00,  4.300e+00, -8.000e+00,\n",
       "         1.810e+00,  1.830e+00,  9.300e+00,  1.100e+01,  6.600e+00,\n",
       "         1.970e+00,  1.180e+01,  1.390e+01,  8.600e+00,  2.800e+00,\n",
       "         6.000e-01,  8.800e-01,  0.000e+00,  1.580e+02,  4.600e-01,\n",
       "         1.080e+00,  1.600e+00,  4.700e-01,  1.003e+00,  1.799e+00,\n",
       "         2.400e-01,  8.860e-01,  9.700e-01,  1.450e+00,  5.100e-01,\n",
       "         1.810e+00,  1.540e+00,  2.600e+00,  5.200e+00,  5.960e+00,\n",
       "         9.600e+01]),\n",
       " 'L': array([ 2.360e+00,  9.600e+00,  7.000e+00,  6.040e+00,  1.310e+02,\n",
       "         6.000e+00,  2.140e+01,  1.300e-01,  4.900e+00,  1.878e+01,\n",
       "         8.500e+01,  1.060e+00,  1.220e+00, -1.800e+00,  3.800e+00,\n",
       "         1.490e+01,  2.460e+00,  9.430e-01, -1.650e+00,  1.700e+00,\n",
       "        -1.180e+00,  5.000e-01,  8.470e+00,  1.470e+00,  1.820e+00,\n",
       "         1.530e+00,  2.280e+00,  7.500e-01,  6.600e+00, -9.200e+00,\n",
       "         1.800e+00,  1.800e+00,  1.000e+01,  1.500e+01,  2.000e+01,\n",
       "         1.820e+00,  1.000e+01,  8.800e+00,  1.170e+01,  4.800e+00,\n",
       "         4.500e-01,  8.500e-01,  0.000e+00,  1.641e+02,  3.700e-01,\n",
       "         1.210e+00,  1.300e+00,  5.900e-01,  1.236e+00,  1.261e+00,\n",
       "         6.700e-01,  8.100e-01,  1.300e+00,  1.020e+00,  5.800e-01,\n",
       "         1.300e+00,  1.260e+00,  1.420e+00,  9.000e+00,  9.660e+00,\n",
       "         4.000e+01]),\n",
       " 'K': array([ 2.200e+00,  8.900e+00,  1.028e+01,  9.470e+00,  1.460e+02,\n",
       "         2.000e+00,  1.571e+01,  4.950e+01,  1.130e+01,  2.129e+01,\n",
       "         8.700e+01, -1.500e+00, -6.700e-01,  3.000e+00, -3.900e+00,\n",
       "         1.136e+01, -2.450e+00,  2.830e-01,  4.600e-01, -9.900e-01,\n",
       "         1.400e+00, -1.800e+00,  2.950e+00,  9.000e-02, -2.770e+00,\n",
       "        -1.500e+00, -9.520e+00,  2.060e+00, -3.600e+00,  5.700e+00,\n",
       "        -2.030e+00, -1.540e+00,  1.300e+00, -2.500e+00, -3.700e+00,\n",
       "        -3.460e+00, -3.200e+00,  1.000e-01,  5.000e-01,  1.030e+01,\n",
       "         3.000e-02,  5.200e-01,  3.300e-01,  1.155e+02,  4.700e-01,\n",
       "         1.160e+00,  7.400e-01,  1.010e+00,  1.172e+00,  7.210e-01,\n",
       "         1.302e+00,  8.970e-01,  1.230e+00,  7.700e-01,  9.600e-01,\n",
       "         7.000e-01,  7.400e-01,  5.900e-01,  5.700e+00,  5.840e+00,\n",
       "         5.600e+01]),\n",
       " 'M': array([  2.28 ,   9.21 ,   7.   ,   5.74 , 149.   ,   1.   ,  16.25 ,\n",
       "          1.43 ,   5.7  ,  21.64 ,  80.   ,   0.64 ,   1.02 ,  -1.3  ,\n",
       "          1.9  ,  14.39 ,   1.1  ,   0.738,  -0.66 ,   1.23 ,  -1.59 ,\n",
       "          0.4  ,   8.95 ,   1.42 ,   0.96 ,   0.64 ,  -1.48 ,  -3.85 ,\n",
       "          2.5  ,  -4.2  ,   1.18 ,   1.1  ,   8.7  ,   4.1  ,   5.6  ,\n",
       "          1.4  ,   7.1  ,   4.8  ,   1.9  ,   1.   ,   0.4  ,   0.85 ,\n",
       "          0.   , 172.9  ,   0.3  ,   1.45 ,   1.05 ,   0.6  ,   1.363,\n",
       "          1.21 ,   0.436,   0.81 ,   1.47 ,   0.97 ,   0.41 ,   1.19 ,\n",
       "          1.09 ,   1.49 ,   2.4  ,   2.42 ,  94.   ]),\n",
       " 'F': array([  2.58 ,   9.24 ,   7.   ,   5.91 , 165.   ,   2.   ,  19.8  ,\n",
       "          0.35 ,   5.2  ,  29.4  ,  81.   ,   1.19 ,   1.92 ,  -2.5  ,\n",
       "          2.8  ,  14.   ,   2.54 ,   1.   ,  -1.52 ,   1.79 ,  -2.12 ,\n",
       "          0.5  ,   9.03 ,   1.57 ,   2.27 ,   1.19 ,  -0.76 ,  -1.41 ,\n",
       "          7.5  ,  -9.2  ,   1.74 ,   1.69 ,   9.6  ,  14.7  ,  19.2  ,\n",
       "          1.98 ,  13.9  ,  13.2  ,   5.1  ,   2.4  ,   0.5  ,   0.88 ,\n",
       "          0.   , 194.1  ,   0.31 ,   1.13 ,   1.38 ,   0.6  ,   1.195,\n",
       "          1.393,   0.624,   0.797,   1.07 ,   1.32 ,   0.59 ,   1.25 ,\n",
       "          1.23 ,   1.3  ,   3.9  ,   3.86 ,  41.   ]),\n",
       " 'P': array([  1.99 ,  10.6  ,   7.   ,   6.3  , 115.   ,   4.   ,  17.43 ,\n",
       "          1.58 ,   8.   ,  10.93 ,  91.   ,   0.12 ,  -0.49 ,   0.   ,\n",
       "         -1.6  ,  11.37 ,   1.29 ,   0.711,  -0.17 ,   0.72 ,   0.73 ,\n",
       "         -0.3  ,   3.87 ,   0.54 ,   0.99 ,   0.12 ,   0.   ,  -0.53 ,\n",
       "          2.2  ,   2.1  ,   0.86 ,   0.84 ,   4.9  ,   5.6  ,   5.1  ,\n",
       "         -1.44 ,   8.   ,   6.1  ,   2.7  ,   4.8  ,   0.18 ,   0.64 ,\n",
       "          0.39 ,  92.9  ,   0.51 ,   0.57 ,   0.55 ,   1.52 ,   0.492,\n",
       "          0.354,   1.415,   1.54 ,   0.52 ,   0.64 ,   1.91 ,   0.4  ,\n",
       "          0.42 ,   0.35 ,   5.1  ,   4.7  ,  56.   ]),\n",
       " 'S': array([ 2.210e+00,  9.150e+00,  7.000e+00,  5.680e+00,  1.050e+02,\n",
       "         6.000e+00,  9.470e+00,  1.670e+00,  9.200e+00,  6.350e+00,\n",
       "         1.070e+02, -1.800e-01, -5.500e-01,  3.000e-01, -8.000e-01,\n",
       "         1.123e+01, -8.400e-01,  3.590e-01,  4.200e-01, -4.000e-02,\n",
       "         5.200e-01, -1.000e-01,  4.090e+00,  9.700e-01, -1.240e+00,\n",
       "        -1.800e-01, -5.060e+00, -2.600e-01, -6.000e-01,  6.500e+00,\n",
       "        -6.400e-01, -6.300e-01,  3.100e+00, -3.500e+00, -4.100e+00,\n",
       "        -5.300e-01, -3.700e+00,  1.200e+00,  8.000e+00,  9.400e+00,\n",
       "         2.200e-01,  6.600e-01,  1.420e+00,  8.560e+01,  5.100e-01,\n",
       "         7.700e-01,  7.500e-01,  1.430e+00,  7.390e-01,  9.280e-01,\n",
       "         1.316e+00,  1.130e+00,  8.200e-01,  9.500e-01,  1.320e+00,\n",
       "         8.200e-01,  8.700e-01,  7.000e-01,  6.900e+00,  6.560e+00,\n",
       "         1.200e+02]),\n",
       " 'T': array([ 2.150e+00,  9.120e+00,  7.000e+00,  5.600e+00,  1.190e+02,\n",
       "         4.000e+00,  1.577e+01,  1.660e+00,  8.600e+00,  1.101e+01,\n",
       "         9.300e+01, -5.000e-02, -2.800e-01, -4.000e-01, -7.000e-01,\n",
       "         1.169e+01, -4.100e-01,  4.500e-01,  2.900e-01,  2.600e-01,\n",
       "         7.000e-02, -2.000e-01,  4.490e+00,  1.080e+00, -1.000e+00,\n",
       "        -5.000e-02, -4.880e+00, -4.500e-01, -2.200e+00,  5.200e+00,\n",
       "        -2.600e-01, -2.700e-01,  3.500e+00,  1.100e+00,  8.000e-01,\n",
       "        -3.200e-01,  1.500e+00,  2.700e+00,  4.900e+00,  7.000e+00,\n",
       "         2.300e-01,  7.000e-01,  7.100e-01,  1.065e+02,  4.400e-01,\n",
       "         8.300e-01,  1.190e+00,  9.600e-01,  7.850e-01,  1.221e+00,\n",
       "         7.390e-01,  1.148e+00,  8.200e-01,  1.210e+00,  1.040e+00,\n",
       "         1.120e+00,  1.300e+00,  5.900e-01,  5.800e+00,  5.340e+00,\n",
       "         9.700e+01]),\n",
       " 'W': array([ 2.380e+00,  9.390e+00,  7.000e+00,  5.880e+00,  2.040e+02,\n",
       "         1.000e+00,  2.167e+01,  2.100e+00,  5.400e+00,  4.253e+01,\n",
       "         1.040e+02,  8.100e-01,  5.000e-01, -3.400e+00, -9.000e-01,\n",
       "         1.393e+01,  2.560e+00,  8.780e-01, -1.200e+00,  2.250e+00,\n",
       "        -5.100e-01,  3.000e-01,  7.660e+00,  1.000e+00,  2.130e+00,\n",
       "         8.100e-01, -5.880e+00, -1.140e+00,  7.900e+00, -1.000e+01,\n",
       "         1.460e+00,  1.350e+00,  9.200e+00,  1.780e+01,  1.630e+01,\n",
       "         1.530e+00,  1.810e+01,  1.490e+01,  2.200e+00,  1.400e+00,\n",
       "         2.700e-01,  8.500e-01,  1.300e-01,  2.246e+02,  3.100e-01,\n",
       "         1.080e+00,  1.370e+00,  9.600e-01,  1.090e+00,  1.306e+00,\n",
       "         5.460e-01,  9.410e-01,  9.900e-01,  1.140e+00,  7.600e-01,\n",
       "         1.540e+00,  1.750e+00,  8.900e-01,  1.300e+00,  1.080e+00,\n",
       "         1.800e+01]),\n",
       " 'Y': array([ 2.200e+00,  9.110e+00,  1.007e+01,  5.630e+00,  1.810e+02,\n",
       "         2.000e+00,  1.803e+01,  1.610e+00,  6.200e+00,  3.153e+01,\n",
       "         8.400e+01,  2.600e-01,  1.670e+00, -2.300e+00, -1.300e+00,\n",
       "         1.342e+01,  1.630e+00,  8.800e-01, -1.430e+00,  9.600e-01,\n",
       "        -2.100e-01, -4.000e-01,  5.890e+00,  8.300e-01,  1.470e+00,\n",
       "         2.600e-01, -6.110e+00,  1.300e-01,  7.100e+00, -1.900e+00,\n",
       "         5.100e-01,  3.900e-01,  8.000e+00,  3.800e+00,  5.900e+00,\n",
       "         4.900e-01,  8.200e+00,  6.100e+00,  2.600e+00,  5.100e+00,\n",
       "         1.500e-01,  7.600e-01,  2.000e-01,  1.777e+02,  4.200e-01,\n",
       "         6.900e-01,  1.470e+00,  1.140e+00,  7.870e-01,  1.266e+00,\n",
       "         7.950e-01,  1.109e+00,  7.200e-01,  1.250e+00,  1.050e+00,\n",
       "         1.530e+00,  1.680e+00,  1.080e+00,  3.200e+00,  2.920e+00,\n",
       "         4.100e+01]),\n",
       " 'V': array([ 2.290e+00,  9.740e+00,  7.000e+00,  6.020e+00,  1.170e+02,\n",
       "         4.000e+00,  2.157e+01,  1.300e-01,  5.900e+00,  1.392e+01,\n",
       "         8.900e+01,  1.080e+00,  9.100e-01, -1.500e+00,  4.200e+00,\n",
       "         1.571e+01,  1.730e+00,  8.250e-01, -7.500e-01,  1.220e+00,\n",
       "        -1.270e+00,  6.000e-01,  7.630e+00,  1.370e+00,  1.300e+00,\n",
       "         1.800e+00,  1.990e+00, -1.300e-01,  5.900e+00, -3.700e+00,\n",
       "         1.340e+00,  1.320e+00,  8.500e+00,  2.100e+00,  3.500e+00,\n",
       "         1.460e+00,  3.300e+00,  2.700e+00,  1.290e+01,  4.500e+00,\n",
       "         5.400e-01,  8.600e-01,  0.000e+00,  1.410e+02,  3.900e-01,\n",
       "         1.060e+00,  1.700e+00,  5.000e-01,  9.900e-01,  1.965e+00,\n",
       "         3.870e-01,  7.720e-01,  9.100e-01,  1.490e+00,  4.700e-01,\n",
       "         1.810e+00,  1.530e+00,  2.630e+00,  6.600e+00,  6.870e+00,\n",
       "         7.400e+01])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
